{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKTMO                  0\nOKTMO_NAME             0\nOKTMO_SHORT_NAME       0\nID_MONOCITY            0\nMONOCITY_NAME          0\nMONOCITY_FULLNAME      0\nMONOCITY_CATEGORY      0\nMONOCITY_NUM_IN_ACT    0\nDOCLEVELCODE           0\nDOCLEVELNAME           0\nIND_TYPE               0\nIND_NAME               0\ndtype: int64\nКоличество показателей:  19995\n"
     ]
    }
   ],
   "source": [
    "#Анализ показателей стратпланирования по моногородам\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Загрузка даных\n",
    "xl_file = pd.ExcelFile(\"D:/Projects/Aspirantura/GASU_SP/Показатели моногородов.xlsx\")\n",
    "# dfs = {sheet_name: xl_file.parse(sheet_name)\n",
    "#           for sheet_name in xl_file.sheet_names}\n",
    "ds = xl_file.parse(\"Лист1\")\n",
    "print(ds.apply(lambda x: sum(x.isnull()),axis=0)) #missing values\n",
    "print(\"Количество показателей: \",len(ds))\n",
    "#ds = pd.read_csv(\"D:/projects/Aspirantura/GASU_SP/20161017_gasu_sp_exp01.dsv\", encoding='cp1251', sep='|', lineterminator='\\r') #Reading the dataset in a dataframe using Pandas\n",
    "#ds.describe()\n",
    "#ds.INDS.value_counts() #количество показателей по уровням власти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     D:\\Users\\PDudarin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     D:\\Users\\PDudarin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nDone\n"
     ]
    }
   ],
   "source": [
    "# Подготовительная часть\n",
    "# включаем возможности стемминга\n",
    "import pymorphy2\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "nltk.download('punkt')  #не знаю нужно ли каждый раз это скачивать\n",
    "nltk.download('stopwords')  #не знаю нужно ли каждый раз это скачивать\n",
    "g_path = \"D:/Projects/Aspirantura/GASU_SP/\"\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатели до стемминга ДОЛЯ НАСЕЛЕНИЯ ИМЕЮЩЕГО ДЕНЕЖНЫЕ ДОХОДЫ НИЖЕ ВЕЛИЧИНЫ ПРОЖИТОЧНОГО МИНИМУМА В ОБЩЕЙ ЧИСЛЕННОСТИ НАСЕЛЕНИЯ АЛЕЙСКОГО РАЙОНА АЛТАЙСКОГО КРАЯ\nПоказатели до стемминга КОЛИЧЕСТВО ИСТОРИКОПАТРИОТИЧЕСКИХ ГЕРОИКОПАТРИОТИЧЕСКИХ И ВОЕННОПАТРИОТИЧЕСКИХ МУЗЕЕВ ИЛИ МУЗЕЙНЫХ КОМНАТ В ОБЩЕОБРАЗОВАТЕЛЬНЫХ УЧРЕЖДЕНИЯХ\nПоказатели до стемминга ОХВАТ ПРОФИЛАКТИЧЕСКИМИ МЕРАМИ ПОДРОСТКОВ И МОЛОДЕЖИ В ВОЗРАСТЕ ОТ ДО ЛЕТ\nПоказатели до стемминга УРОВЕНЬ ЗАНЯТОСТИ НАСЕЛЕНИЯ\nПоказатели до стемминга УДЕЛЬНЫЙ ВЕС РАБОТНИКОВ С ПРОФЕССИОНАЛЬНЫМ ОБРАЗОВАНИЕМ В ОБЩЕЙ ЧИСЛЕННОСТИ ЗАНЯТЫХ В ЭКОНОМИКЕ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатели после стемминга ['доля', 'население', 'иметь', 'денежный', 'доход', 'ниже', 'величина', 'прожиточный', 'минимум', 'в', 'общий', 'численность', 'население', 'алейский', 'район', 'алтайский', 'край']\nПоказатели после стемминга ['количество', 'историкопатриотический', 'героикопатриотический', 'и', 'военнопатриотический', 'музей', 'или', 'музейный', 'комната', 'в', 'общеобразовательный', 'учреждение']\nПоказатели после стемминга ['охват', 'профилактический', 'мера', 'подросток', 'и', 'молодёжь', 'в', 'возраст', 'от', 'до', 'год']\nПоказатели после стемминга ['уровень', 'занятость', 'население']\nПоказатели после стемминга ['удельный', 'вес', 'работник', 'с', 'профессиональный', 'образование', 'в', 'общий', 'численность', 'занятой', 'в', 'экономика']\nТоп 10 слов:  [('в', 11499), ('и', 7217), ('количество', 5445), ('доля', 4409), ('на', 4254), ('общий', 3971), ('муниципальный', 3746), ('по', 2962), ('с', 2079), ('от', 1925)]\nВсего разных слов:  6766\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "#s = ds.INDS.str.upper().tolist()[0]\n",
    "print(\"Показатели до стемминга\", ds.IND_NAME.str.upper().tolist()[0])\n",
    "print(\"Показатели до стемминга\", ds.IND_NAME.str.upper().tolist()[1])\n",
    "print(\"Показатели до стемминга\", ds.IND_NAME.str.upper().tolist()[2])\n",
    "print(\"Показатели до стемминга\", ds.IND_NAME.str.upper().tolist()[3])\n",
    "print(\"Показатели до стемминга\", ds.IND_NAME.str.upper().tolist()[4])\n",
    "#print(\"Показатели до стемминга\",ds.INDS.str.upper().tolist())\n",
    "#pymorphy2.tokenizers.simple_word_tokenize(s)\n",
    "#nltk.word_tokenize(s)\n",
    "#ds['IND_NAME_TOKENIZED'] = ds.apply(lambda x: x[\"IND_NAME\"], axis=1)\n",
    "#morph.parse(s)[0].normal_form\n",
    "#morph.parse('использованных')[0].normal_form\n",
    "\n",
    "#TODO хотелось бы сделать новую фичу IND_NAME_TOKENIZED и ее токенизировать, но пока не получается\n",
    "\n",
    "# dfs = {sheet_name: xl_file.parse(sheet_name)\n",
    "#           for sheet_name in xl_file.sheet_names}\n",
    "\n",
    "inds = {0 : ''}\n",
    "i = 0\n",
    "words = collections.Counter()\n",
    "\n",
    "\n",
    "chars_to_remove = [u'«', u'»', u'!', u'<', u'>', u'?', u',', u'.', u'-', u'(', u')', u'[', u']', u'\"']\n",
    "dd = {ord(c):' ' for c in chars_to_remove}\n",
    "\n",
    "for j in ds.IND_NAME.str.upper().tolist():\n",
    "  # try:\n",
    "  inds[i] = [morph.parse(x)[0].normal_form for x in nltk.word_tokenize(j.translate(dd))]\n",
    "  for w in inds[i]:\n",
    "      words[w] += 1\n",
    "\n",
    "                                      # TODO выяснить какие строки он не в состоянии обработать\n",
    "          #txts[0] = ' '.join(nltk.word_tokenize(j))\n",
    "  i=i+1\n",
    "  # except:\n",
    "  #   print(\"Unable to tokenize \", j)\n",
    "\n",
    "print(\"Показатели после стемминга\",inds[0])\n",
    "print(\"Показатели после стемминга\",inds[1])\n",
    "print(\"Показатели после стемминга\",inds[2])\n",
    "print(\"Показатели после стемминга\",inds[3])\n",
    "print(\"Показатели после стемминга\",inds[4])\n",
    "\n",
    "print(\"Топ 10 слов: \",words.most_common(10))\n",
    "print(\"Всего разных слов: \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во стоп слов:  372\nТоп 10 слов после очистки:  [('население', 1852), ('ребёнок', 1519), ('услуга', 1447), ('городской', 1416), ('мероприятие', 1314), ('округа', 1215), ('гражданин', 1103), ('бюджет', 1054), ('город', 1038), ('территория', 1018)]\nВсего разных слов после очистки:  6574\n"
     ]
    }
   ],
   "source": [
    "#Загрузка стоп слов\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "xl_file = pd.ExcelFile(\"D:/Projects/Aspirantura/GASU_SP/Стоп слова.xlsx\")\n",
    "# dfs = {sheet_name: xl_file.parse(sheet_name)\n",
    "#           for sheet_name in xl_file.sheet_names}\n",
    "ds_stop_words = xl_file.parse(\"Лист1\")\n",
    "\n",
    "stop_list = [morph.parse(x)[0].normal_form for x in ds_stop_words.STOP_WORDS.str.upper().tolist() ]\n",
    "nltk_stop_words = stopwords.words('russian')\n",
    "for w in nltk_stop_words:\n",
    "    stop_list.append(w)\n",
    "\n",
    "print(\"Кол-во стоп слов: \",len(stop_list))\n",
    "\n",
    "#Уберем стоп слова из нашего массива\n",
    "for w in list(words):\n",
    "    if w in stop_list:\n",
    "        del words[w]\n",
    "\n",
    "print(\"Топ 10 слов после очистки: \",words.most_common(10))\n",
    "print(\"Всего разных слов после очистки: \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Записано пар слов:  21869191\n",
      "--- 138.5899999141693 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#create Dictionay of word pairs\n",
    "import pickle\n",
    "import time\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "i=0;\n",
    "d = {}\n",
    "\n",
    "for w1 in words:\n",
    "    for w2 in words:\n",
    "        # if w1>w2 and i<10000:\n",
    "        if w1>w2:\n",
    "            i+=1\n",
    "            d[w1+'__'+w2] = None\n",
    "            # time.sleep(0.5) # delays for 1/2 seconds\n",
    "            # resp = requests.get('http://ling.go.mail.ru/dsm/ruwikiruscorpora/'+w1+'__'+w2+'/api/similarity/')\n",
    "            # if resp.status_code != 200:\n",
    "            #   # This means something went wrong.\n",
    "            #   print(\"Error with service RusVectores \", w1,\" - \",w2)\n",
    "            # else:\n",
    "            #   d[w1+'#'+w2] = (nltk.word_tokenize(resp.text)[0])\n",
    "\n",
    "output = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities.pkl', 'wb')\n",
    "pickle.dump(d, output)\n",
    "output.close()\n",
    "print(\"Записано пар слов: \", i)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start time Fri, 17 Feb 2017 10:18:03 ---\n",
      "Already processed pair count:  770661\n",
      "--- 508.2660000324249 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Перенесем данные по парам слов из старого справочника в новый\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import pickle\n",
    "\n",
    "print(\"--- Start time %s ---\" % strftime(\"%a, %d %b %Y %H:%M:%S\", gmtime()))\n",
    "start_time = time.time()\n",
    "\n",
    "pkl_file_old = open('D:/Projects/Python/20161210_StratPlanClusters/words_sem_dict2.pkl', 'rb')\n",
    "d_old = pickle.load(pkl_file_old)\n",
    "pkl_file_old.close()\n",
    "\n",
    "pkl_file_new = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem.pkl', 'rb')\n",
    "d_new = pickle.load(pkl_file_new)\n",
    "pkl_file_new.close()\n",
    "\n",
    "for w2, v in d_old.items():\n",
    "  if w2 in d_new.keys():\n",
    "      d_new[w2] = v\n",
    "\n",
    "output = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem.pkl', 'wb')\n",
    "pickle.dump(d_new, output)\n",
    "output.close()\n",
    "\n",
    "l = {k for k, v in d_new.items() if v is not None } #all the empty\n",
    "print(\"Already processed pair count: \", len(l))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed pair count:  770661\n",
      "Sample  индивидуальный__бюджетный  -  0.0902280646743\n",
      "Sample  природный__автоматический  -  -0.0183039430446\n",
      "Sample  модернизация__дело  -  0.0323260518363\n",
      "Sample  коммуникационный__квалифицировать  -  0.00406434728715\n",
      "Sample  оздоровление__зарубежный  -  0.0369522816396\n",
      "Sample  теплов__магистральный  -  -0.0187530035771\n",
      "Sample  профилактика__проезд  -  0.0581372491988\n",
      "Sample  течение__объединение  -  0.0761837203231\n",
      "Sample  потребность__вещество  -  0.043745834564\n",
      "Sample  энергоэффективность__технически  -  0.0175944903677\n",
      "Sample  рекультивированный__признанный  -  0.00087841042564\n"
     ]
    }
   ],
   "source": [
    "# test new dictionary \n",
    "import pickle\n",
    "\n",
    "# pkl_file_new = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem.pkl', 'rb')\n",
    "# d_new = pickle.load(pkl_file_new)\n",
    "# pkl_file_new.close()\n",
    "\n",
    "l = {k for k, v in d_new.items() if v is not None } #all the empty\n",
    "print(\"Already processed pair count: \", len(l))\n",
    "j = 0\n",
    "\n",
    "for i in l:\n",
    "    j+=1\n",
    "    print(\"Sample \", i, \" - \", d_new.get(i))\n",
    "    if j>10:\n",
    "        break\n",
    "    \n",
    "    \n",
    "# print(\"Sample \", l(1), \" - \",d_new.get(l(1)))\n",
    "# print(\"Sample \", l[10], \" - \",d_new.get(l[10]))\n",
    "# print(\"Sample \", l[100], \" - \",d_new.get(l[100]))\n",
    "# print(\"Sample \", l[1000], \" - \",d_new.get(l[1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start time Thu, 30 Mar 2017 06:09:32 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with service RusVectores  муж__пьяница\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with service RusVectores  жена__муж\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with service RusVectores  вино__водка\nTest fill_sem_dict results:   {'муж__пьяница': 'Error', 'жена__муж': 'Error', 'вино__водка': 'Error'}\nTest: !!! FAILED !!!\nTest join_sem_dicts results:   {'он_она': 0.9, 'я_ты': 0.5, 'я_она': 0.1}\nTest: Passed\nTest split_word_dict results (word_dict_source):   {}\nTest split_word_dict results (word_lists):   [['он_она', 'я_она'], ['я_ты']]\nTest: !!! FAILED !!!\nDone\n--- 0.7840783596038818 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# подготовим функции для последующей параллельной работы\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import pickle\n",
    "\n",
    "print(\"--- Start time %s ---\" % strftime(\"%a, %d %b %Y %H:%M:%S\", gmtime()))\n",
    "start_time = time.time()\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "def fill_sem_dict(p_words):\n",
    "    l_dict = {}\n",
    "    for w in p_words:\n",
    "        #time.sleep(0.1) # delays in secs\n",
    "        for it in range(0,3):\n",
    "          resp = requests.get('http://ling.go.mail.ru/dsm/ruwikiruscorpora/'+w.replace(\"ё\",\"е\")+'/api/similarity/')\n",
    "          if resp.status_code == 200:\n",
    "              break\n",
    "        if resp.status_code != 200:\n",
    "          # This means something went wrong.\n",
    "          print(\"Error with service RusVectores \", w)\n",
    "          l_dict[w] = 'Error'\n",
    "        else:\n",
    "          l_dict[w] = nltk.word_tokenize(resp.text)[0]\n",
    "    return l_dict\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "def merge_sem_dicts(p_sem_dict, p_sem_dict_list):\n",
    "\n",
    "    for d in p_sem_dict_list:\n",
    "        for w, v in d.items():\n",
    "           p_sem_dict[w] = v\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "def split_word_dict(p_word_dict_source, p_list_count, p_list_len):\n",
    "    l_word_list = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    l_word_lists = []\n",
    "    l_word_list = []\n",
    "    for w,v in p_word_dict_source.items():\n",
    "        l_word_list.append(w)\n",
    "        p_word_dict_source[w] = 'Processed'\n",
    "        j +=1\n",
    "        if j >= p_list_len:\n",
    "            l_word_lists.append(l_word_list)\n",
    "            l_word_list = []\n",
    "            j = 0\n",
    "            i += 1\n",
    "        if i >= p_list_count:\n",
    "            break\n",
    "\n",
    "    if j != 0:\n",
    "        l_word_lists.append(l_word_list)\n",
    "\n",
    "    p_word_dict_source = {k:v for k, v in p_word_dict_source.items() if v is None }\n",
    "\n",
    "    return [p_word_dict_source, l_word_lists]\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "#   Test functions block\n",
    "#---------------------------------------------------------\n",
    "\n",
    "def test_fill_sem_dict():\n",
    "    sem_dict = fill_sem_dict([\"муж__пьяница\", \"жена__муж\", \"вино__водка\"])\n",
    "    print(\"Test fill_sem_dict results:  \", sem_dict)\n",
    "    res = {'вино__водка': '0.724427524288', 'муж__пьяница': '0.298472315507', 'жена__муж': '0.904485693336'}\n",
    "    if sem_dict == res:\n",
    "        print(\"Test: Passed\")\n",
    "    else:\n",
    "        print(\"Test: !!! FAILED !!!\")\n",
    "\n",
    "def test_merge_sem_dicts():\n",
    "    sem_dict = {}\n",
    "    sem_dict_list = [{\"я_ты\":0.5},{\"он_она\":0.9, \"я_она\":0.1}]\n",
    "    merge_sem_dicts(sem_dict, sem_dict_list)\n",
    "    print(\"Test join_sem_dicts results:  \", sem_dict)\n",
    "    res =  {'он_она': 0.9, 'я_она': 0.1, 'я_ты': 0.5}\n",
    "    if sem_dict == res:\n",
    "        print(\"Test: Passed\")\n",
    "    else:\n",
    "        print(\"Test: !!! FAILED !!!\")\n",
    "\n",
    "def test_split_word_dict():\n",
    "    word_dict_source = {'он_она': 0.9, 'я_она': 0.1, 'я_ты': 0.5}\n",
    "    word_lists = {}\n",
    "    [word_dict_source, word_lists] = split_word_dict(word_dict_source, 2, 2)\n",
    "    print(\"Test split_word_dict results (word_dict_source):  \", word_dict_source)\n",
    "    print(\"Test split_word_dict results (word_lists):  \", word_lists)\n",
    "    res =  [['я_она', 'я_ты'], ['он_она']]\n",
    "    if (word_lists == res)and(len(word_dict_source)==0):\n",
    "        print(\"Test: Passed\")\n",
    "    else:\n",
    "        print(\"Test: !!! FAILED !!!\")\n",
    "\n",
    "    \n",
    "#---------------------------------------------------------\n",
    "# Testing....\n",
    "\n",
    "test_fill_sem_dict()\n",
    "test_merge_sem_dicts()\n",
    "test_split_word_dict()\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "print(\"Done\")\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union process started...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed pair count:  21869191\nUnion process finished.\n"
     ]
    }
   ],
   "source": [
    "#union dictionaries\n",
    "\n",
    "print(\"Union process started...\")\n",
    "pkl_file = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_14.pkl', 'rb')\n",
    "d_in_2 = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "# pkl_file = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_7.pkl', 'rb')\n",
    "# d_in_3 = pickle.load(pkl_file)\n",
    "# pkl_file.close()\n",
    "#\n",
    "# pkl_file = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_8.pkl', 'rb')\n",
    "# d_in_4 = pickle.load(pkl_file)\n",
    "# pkl_file.close()\n",
    "#\n",
    "# pkl_file = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_9.pkl', 'rb')\n",
    "# d_in_5 = pickle.load(pkl_file)\n",
    "# pkl_file.close()\n",
    "\n",
    "\n",
    "pkl_file = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem.pkl', 'rb')\n",
    "d_out = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "\n",
    "merge_sem_dicts(d_out, [d_in_2])\n",
    "\n",
    "output = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem.pkl', 'wb')\n",
    "pickle.dump(d_out, output)\n",
    "output.close()\n",
    "\n",
    "l_sem_dict_not_empty = {k:v for k, v in d_out.items() if v is not None } #all not empty\n",
    "print(\"Already processed pair count: \", len(l_sem_dict_not_empty))\n",
    "print(\"Union process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start time Tue, 28 Mar 2017 08:31:55 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_out_dict_file_name 13length:  721150\nDone\n--- 108.36269521713257 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------\n",
    "# Разрезать файл (семантический словарь) на мелкие куски\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "def split_sem_dictionary(p_in_dict_file_name, p_out_dict_file_name, p_num_start, p_dict_cnt, p_dict_len):\n",
    "\n",
    "    print(\"--- Start time %s ---\" % strftime(\"%a, %d %b %Y %H:%M:%S\", gmtime()))\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    pkl_file = open(p_in_dict_file_name, 'rb')\n",
    "    d = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    l_small_dict = {}\n",
    "    i = 0\n",
    "    j = p_num_start\n",
    "    for k, v in d.items():\n",
    "\n",
    "        if v is None:\n",
    "            i += 1\n",
    "            l_small_dict[k] = v\n",
    "\n",
    "        if i>=p_dict_len:\n",
    "            output = open(p_out_dict_file_name+str(j), 'wb')\n",
    "            pickle.dump(l_small_dict, output)\n",
    "            output.close()\n",
    "            print(\"p_out_dict_file_name \"+str(j)+\" length: \", len(l_small_dict))\n",
    "            l_small_dict = {}\n",
    "            i = 0\n",
    "            j += 1\n",
    "            if j >= p_dict_cnt+p_num_start:\n",
    "                break\n",
    "\n",
    "    if len(l_small_dict) > 0:\n",
    "        output = open(p_out_dict_file_name+str(j), 'wb')\n",
    "        pickle.dump(l_small_dict, output)\n",
    "        output.close()\n",
    "        print(\"p_out_dict_file_name \"+str(j)+\"length: \", len(l_small_dict))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Done\")\n",
    "    print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "split_sem_dictionary('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem.pkl',\n",
    "                     'D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_.pkl',\n",
    "                     13,\n",
    "                     1,\n",
    "                     3000000\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "#---------------------------------------------------------\n",
    "#---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start time Mon, 13 Mar 2017 20:06:10 ---\nStart get_semm_words_from_rus_vectores(..., iter=3, thread=4, list_cnt=16, list_len=1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed pair count:  0\n--- Iteration # 1 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7690439224243164 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 646.3829710483551 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 649.442146062851 seconds ---\n--- Iteration # 2 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8840503692626953 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 644.1898455619812 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 646.3459687232971 seconds ---\n--- Iteration # 3 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8210468292236328 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 648.7621068954468 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 650.9152302742004 seconds ---\n--- Iteration # 4 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8540487289428711 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 649.4601469039917 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 651.6682732105255 seconds ---\n--- Iteration # 5 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8810503482818604 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 649.9531750679016 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 652.2233049869537 seconds ---\n--- Iteration # 6 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.9100520610809326 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 648.6551008224487 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 650.8812282085419 seconds ---\n--- Iteration # 7 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8860507011413574 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 645.3699128627777 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 647.6360428333282 seconds ---\n--- Iteration # 8 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8780500888824463 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 643.2187900543213 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 645.4479174613953 seconds ---\n--- Iteration # 9 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8880507946014404 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 653.6093842983246 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 655.8295111656189 seconds ---\n--- Iteration # 10 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.836047887802124 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 654.0684103965759 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 656.2535355091095 seconds ---\n--- Iteration # 11 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8470485210418701 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 648.4580895900726 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 650.6612157821655 seconds ---\n--- Iteration # 12 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8600490093231201 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 650.4312026500702 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 652.6583299636841 seconds ---\n--- Iteration # 13 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8500485420227051 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 641.4396884441376 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.7138183116913 seconds ---\n--- Iteration # 14 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8480486869812012 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 646.8839995861053 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 649.1521294116974 seconds ---\n--- Iteration # 15 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8820505142211914 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 652.124299287796 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 654.356427192688 seconds ---\n--- Iteration # 16 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8580491542816162 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 654.1524152755737 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 656.399543762207 seconds ---\n--- Iteration # 17 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.844048261642456 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 653.9554040431976 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 656.1655304431915 seconds ---\n--- Iteration # 18 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8490486145019531 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 655.1644732952118 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 657.3866002559662 seconds ---\n--- Iteration # 19 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.844048261642456 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 652.4183163642883 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 654.6244425773621 seconds ---\n--- Iteration # 20 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8310472965240479 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 649.7861657142639 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 651.9762907028198 seconds ---\n--- Iteration # 21 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8370480537414551 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 641.7177042961121 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.944831609726 seconds ---\n--- Iteration # 22 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.842048168182373 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 641.6577005386353 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.8658268451691 seconds ---\n--- Iteration # 23 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8580491542816162 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 647.8300535678864 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 650.127185344696 seconds ---\n--- Iteration # 24 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8660495281219482 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 642.6827592849731 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 644.9258875846863 seconds ---\n--- Iteration # 25 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8100464344024658 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 641.5046920776367 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.7648212909698 seconds ---\n--- Iteration # 26 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8170468807220459 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 653.6143846511841 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 655.824511051178 seconds ---\n--- Iteration # 27 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7990455627441406 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 648.015064239502 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 650.2691931724548 seconds ---\n--- Iteration # 28 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8660495281219482 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 643.7728216648102 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 646.051952123642 seconds ---\n--- Iteration # 29 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8130466938018799 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 642.4987487792969 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 644.7498776912689 seconds ---\n--- Iteration # 30 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8330478668212891 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 649.8621699810028 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 652.1643018722534 seconds ---\n--- Iteration # 31 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8000457286834717 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 652.1813027858734 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 654.4024295806885 seconds ---\n--- Iteration # 32 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7880449295043945 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 651.1112413406372 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 653.3813712596893 seconds ---\n--- Iteration # 33 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8040459156036377 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 651.2432489395142 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 653.5353801250458 seconds ---\n--- Iteration # 34 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7990458011627197 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 650.8292253017426 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 653.0823543071747 seconds ---\n--- Iteration # 35 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.8030459880828857 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 644.3168528079987 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 646.5019779205322 seconds ---\n--- Iteration # 36 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7900452613830566 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 638.4235157966614 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 640.6556434631348 seconds ---\n--- Iteration # 37 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7650437355041504 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 667.7591936588287 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 670.023323059082 seconds ---\n--- Iteration # 38 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7880451679229736 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 650.1131844520569 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 652.2983093261719 seconds ---\n--- Iteration # 39 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7760443687438965 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 647.3790278434753 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 649.6121556758881 seconds ---\n--- Iteration # 40 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7670438289642334 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 650.4232022762299 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 652.6613302230835 seconds ---\n--- Iteration # 41 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7990458011627197 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 639.583582162857 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 641.8257102966309 seconds ---\n--- Iteration # 42 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7970454692840576 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 641.1096694469452 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.3557977676392 seconds ---\n--- Iteration # 43 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7760446071624756 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 640.6386425495148 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 642.8697702884674 seconds ---\n--- Iteration # 44 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7520430088043213 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 641.1746730804443 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.451803445816 seconds ---\n--- Iteration # 45 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7680439949035645 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 643.9048292636871 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 646.2209618091583 seconds ---\n--- Iteration # 46 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7800447940826416 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 655.8095102310181 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 658.0706396102905 seconds ---\n--- Iteration # 47 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7300417423248291 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 648.8101098537445 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 651.0272364616394 seconds ---\n--- Iteration # 48 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7830448150634766 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 640.9036576747894 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 643.1457858085632 seconds ---\n--- Iteration # 49 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7640438079833984 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 650.1701874732971 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 652.3873145580292 seconds ---\n--- Iteration # 50 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7830448150634766 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 652.9323456287384 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 655.2134761810303 seconds ---\n--- Iteration # 51 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7590434551239014 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 652.6853313446045 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 654.9074585437775 seconds ---\n--- Iteration # 52 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7480428218841553 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 655.860512971878 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 658.0736398696899 seconds ---\n--- Iteration # 53 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7680437564849854 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pool word time 643.8188242912292 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration successed\n--- 646.1019549369812 seconds ---\n--- Iteration # 54 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split words time 0.7680437564849854 seconds ---\nБудет записано пар слов:  8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with service RusVectores  размещениен__многообразие\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with service RusVectores  понеснный__инвалидовколясочник\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='ling.go.mail.ru', port=80): Max retries exceeded with url: /dsm/ruwikiruscorpora/%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D1%8C__%D1%81%D0%BE%D1%81%D0%BE%D1%82%D0%BE%D1%8F%D1%89%D0%B8%D0%B9/api/similarity/ (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000002943B4E0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 142\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 11004] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, **response_kw)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 151\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <requests.packages.urllib3.connection.HTTPConnection object at 0x000000002943B4E0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m                 )\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, **response_kw)\u001b[0m\n\u001b[1;32m    639\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 640\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='ling.go.mail.ru', port=80): Max retries exceeded with url: /dsm/ruwikiruscorpora/%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D1%8C__%D1%81%D0%BE%D1%81%D0%BE%D1%82%D0%BE%D1%8F%D1%89%D0%B8%D0%B9/api/similarity/ (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000002943B4E0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0c85a0f9546c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m get_semm_words_from_rus_vectores('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_9.pkl'\n\u001b[1;32m     61\u001b[0m                                  \u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                                  4, 8, 1000)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[1;31m#---------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0c85a0f9546c>\u001b[0m in \u001b[0;36mget_semm_words_from_rus_vectores\u001b[0;34m(p_dict_file_name, p_iteration_cnt, p_thread_cnt, p_word_list_cnt, p_word_list_len)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpool_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0ml_sem_dict_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_sem_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_word_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mpool_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--- Pool word time %s seconds ---\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpool_end_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpool_start_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ef1307a2f166>\u001b[0m in \u001b[0;36mfill_sem_dict\u001b[0;34m(p_words)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[1;31m#time.sleep(0.1) # delays in secs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://ling.go.mail.ru/dsm/ruwikiruscorpora/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/api/similarity/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    473\u001b[0m         }\n\u001b[1;32m    474\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\PDudarin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='ling.go.mail.ru', port=80): Max retries exceeded with url: /dsm/ruwikiruscorpora/%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D1%8C__%D1%81%D0%BE%D1%81%D0%BE%D1%82%D0%BE%D1%8F%D1%89%D0%B8%D0%B9/api/similarity/ (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000002943B4E0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#паралельное получение пар слов из сервиса\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import pickle\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "\n",
    "print(\"--- Start time %s ---\" % strftime(\"%a, %d %b %Y %H:%M:%S\", gmtime()))\n",
    "total_start_time = time.time()\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "def get_semm_words_from_rus_vectores(p_dict_file_name, p_iteration_cnt,\n",
    "                                     p_thread_cnt, p_word_list_cnt, p_word_list_len):\n",
    "\n",
    "\n",
    "    pkl_file = open(p_dict_file_name, 'rb')\n",
    "    d = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    l_sem_dict_empty = {k:v for k, v in d.items() if v is None } #all not empty\n",
    "    print(\"Already processed pair count: \", len(d)-len(l_sem_dict_empty))\n",
    "\n",
    "    pool = ThreadPool(p_thread_cnt)\n",
    "\n",
    "    for j in range(1, p_iteration_cnt+1):\n",
    "        print(\"--- Iteration # %s ---\" % j)\n",
    "        start_time = time.time()\n",
    "\n",
    "        l_sem_dict_empty_cnt1 = len(l_sem_dict_empty)\n",
    "        if len(l_sem_dict_empty)==0:\n",
    "            break\n",
    "        split_start_time = time.time()\n",
    "        [l_sem_dict_empty, l_word_lists] = split_word_dict(l_sem_dict_empty, p_word_list_cnt,\n",
    "                                                           p_word_list_len)\n",
    "        split_end_time = time.time()\n",
    "        print(\"--- Split words time %s seconds ---\" % (split_end_time - split_start_time))\n",
    "        l_sem_dict_empty_cnt2 = len(l_sem_dict_empty)\n",
    "        print(\"Будет записано пар слов: \", l_sem_dict_empty_cnt1-l_sem_dict_empty_cnt2)\n",
    "\n",
    "        pool_start_time = time.time()\n",
    "        l_sem_dict_list = pool.map(fill_sem_dict, l_word_lists)\n",
    "        pool_end_time = time.time()\n",
    "        print(\"--- Pool word time %s seconds ---\" % (pool_end_time - pool_start_time))\n",
    "\n",
    "        merge_sem_dicts(d, l_sem_dict_list)\n",
    "\n",
    "        output = open(p_dict_file_name, 'wb')\n",
    "        pickle.dump(d, output)\n",
    "        output.close()\n",
    "        end_time = time.time()\n",
    "        print(\"iteration successed\")\n",
    "        print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "print(\"Start get_semm_words_from_rus_vectores(..., iter=3, thread=4, list_cnt=16, list_len=1000)\")\n",
    "get_semm_words_from_rus_vectores('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem_small_9.pkl'\n",
    "                                 , 100,\n",
    "                                 4, 8, 1000)\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "print(\"Done\")\n",
    "total_end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (total_end_time - total_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пар слов с ё >>  662010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Проверки и корректировки. Временное\n",
    "\n",
    "pkl_file = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem1.pkl', 'rb')\n",
    "d = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "#найти все пары с \"ребЁнок\" и поставить как необработанные\n",
    "i = 0\n",
    "for k,v in d.items():\n",
    "    if (\"ё\" in k) and (v in [\"Unknown\",\"Error\"]):\n",
    "        i += 1\n",
    "        d[k] = None\n",
    "\n",
    "print(\"Пар слов с ё >> \", i)\n",
    "output = open('D:/Projects/Aspirantura/GASU_SP/words_dict_monocities_sem1.pkl', 'wb')\n",
    "pickle.dump(d, output)\n",
    "output.close()\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "# pkl_file = open(g_path+'monocity_words_ds_'+str(g_max_inds_count)+'.pkl', 'rb')\n",
    "# words_ds = pickle.load(pkl_file)\n",
    "# pkl_file.close()\n",
    "# print(\"words_ds len: \", len(words_ds))\n",
    "\n",
    "\n",
    "# pkl_file = open(g_path+'monocity_words_'+str(g_max_inds_count)+'.pkl', 'rb')\n",
    "# words = pickle.load(pkl_file)\n",
    "# pkl_file.close()\n",
    "# print(\"words len: \", len(words))\n",
    "\n",
    "# l_cnt = 0\n",
    "# # for ws in words_ds:\n",
    "# #   if max(w for w in ws if w != 1)  < 0.001:\n",
    "# #       l_cnt +=1\n",
    "# print(\"l_cnt >> \", l_cnt)\n",
    "# print(l_words_sem_dist_dict[\"ребёнок__девочка\"])\n",
    "# # print(l_words_sem_dist_dict[\"девочка__ребёнок\"])\n",
    "# print(l_words_sem_dist_dict[\"факт__оборот\"])\n",
    "# print(l_words_sem_dist_dict[\"оборот__факт\"])\n",
    "# print(\"None cnt >> \", sum(1 for k,v in l_words_sem_dist_dict.items() if v==None))\n",
    "# print(\"Error cnt >> \",sum(1 for k,v in l_words_sem_dist_dict.items() if v=='Error'))\n",
    "# print(\"Unknown cnt >> \", sum(1 for k,v in l_words_sem_dist_dict.items() if v=='Unknown'))\n",
    "\n",
    "# i = 0\n",
    "# print(\"Unknown pairs:\")\n",
    "# for k,v in l_words_sem_dist_dict.items():\n",
    "#     if v == \"Unknown\":\n",
    "#       print(k)\n",
    "#       i += 1\n",
    "#     if i > 10:\n",
    "#         break\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}